[
    {
        "year": "2023",
        "title": "Federated Submodel Optimization for Hot and Cold Data Features",
        "conference_name": "Advances in Neural Information Processing Systems 35  (NeurIPS 2022)",
        "authors": "Yucheng Ding, Chaoyue Niu, Fan Wu, Shaojie Tang, Chengfei Lyu, yanghe feng, Guihai Chen",
        "paper_link": "https:\/\/papers.nips.cc\/paper_files\/paper\/2022\/file\/002262941c9edfd472a79298b2ac5e17-Paper-Conference.pdf",
        "abstract_text": "We focus on federated learning in practical recommender systems and natural language processing scenarios. The global model for federated optimization typically contains a large and sparse embedding layer, while each client\u2019s local data tend to interact with part of features, updating only a small submodel with the feature-related embedding vectors. We identify a new and important issue that distinct data features normally involve different numbers of clients, generating the differentiation of hot and cold features. We further reveal that the classical federated averaging algorithm (FedAvg) or its variants, which randomly selects clients to participate and uniformly averages their submodel updates, will be severely slowed down, because different parameters of the global model are optimized at different speeds. More specifically, the model parameters related to hot (resp., cold) features will be updated quickly (resp., slowly). We thus propose federated submodel averaging (FedSubAvg), which introduces the number of feature-related clients as the metric of feature heat to correct the aggregation of submodel updates. We prove that due to the dispersion of feature heat, the global objective is ill-conditioned, and FedSubAvg works as a suitable diagonal preconditioner. We also rigorously analyze FedSubAvg\u2019s convergence rate to stationary points. We finally evaluate FedSubAvg over several public and industrial datasets. The evaluation results demonstrate that FedSubAvg significantly outperforms FedAvg and its variants.\n"
    },
    {
        "year": "2022",
        "title": "On Kernelized Multi-Armed Bandits with Constraints",
        "conference_name": "Advances in Neural Information Processing Systems 35  (NeurIPS 2022)",
        "authors": "Xingyu Zhou, Bo Ji",
        "paper_link": "https:\/\/papers.nips.cc\/paper_files\/paper\/2022\/file\/00295cede6e1600d344b5cd6d9fd4640-Paper-Conference.pdf",
        "abstract_text": "We study a stochastic bandit problem with a general unknown reward function and a general unknown constraint function. Both functions can be non-linear (even non-convex) and are assumed to lie in a reproducing kernel Hilbert space (RKHS) with a bounded norm. This kernelized bandit setup strictly generalizes standard multi-armed bandits and linear bandits. In contrast to safety-type hard constraints studied in prior works, we consider soft constraints that may be violated in any round as long as the cumulative violations are small, which is motivated by various practical applications. Our ultimate goal is to study how to utilize the nature of soft constraints to attain a finer complexity-regret-constraint trade-off in the kernelized bandit setting. To this end, leveraging primal-dual optimization, we propose a general framework for both algorithm design and performance analysis. This framework builds upon a novel sufficient condition, which not only is satisfied under general exploration strategies, including \\emph{upper confidence bound} (UCB), \\emph{Thompson sampling} (TS), and new ones based on \\emph{random exploration}, but also enables a unified analysis for showing both sublinear regret and sublinear or even zero constraint violation. We demonstrate the superior performance of our proposed algorithms via numerical experiments based on both synthetic and real-world datasets. Along the way, we also make the first detailed comparison between two popular methods for analyzing constrained bandits and Markov decision processes (MDPs) by discussing the key difference and some subtleties in the analysis, which could be of independent interest to the communities.\n"
    },
    {
        "year": "2021",
        "title": "Geometric Order Learning for Rank Estimation",
        "conference_name": "Advances in Neural Information Processing Systems 35  (NeurIPS 2022)",
        "authors": "Seon-Ho Lee, Nyeong Ho Shin, Chang-Su Kim",
        "paper_link": "https:\/\/papers.nips.cc\/paper_files\/paper\/2022\/file\/00358de35a101a372ea0412bed913c86-Paper-Conference.pdf",
        "abstract_text": "A novel approach to rank estimation, called geometric order learning (GOL), is proposed in this paper. First, we construct an embedding space, in which the direction and distance between objects represent order and metric relations between their ranks, by enforcing two geometric constraints: the order constraint compels objects to be sorted according to their ranks, while the metric constraint makes the distance between objects reflect their rank difference. Then, we perform the simple $k$ nearest neighbor ($k$-NN) search in the embedding space to estimate the rank of a test object. Moreover, to assess the quality of embedding spaces for rank estimation, we propose a metric called discriminative ratio for ranking (DRR). Extensive experiments on facial age estimation, historical color image (HCI) classification, and aesthetic score regression demonstrate that GOL constructs effective embedding spaces and thus yields excellent rank estimation performances. The source codes are available at https:\/\/github.com\/seon92\/GOL"
    },
    {
        "year": "2010",
        "title": "Structured Recognition for Generative Models with Explaining Away",
        "conference_name": "Advances in Neural Information Processing Systems 35  (NeurIPS 2022)",
        "authors": "Changmin Yu, Hugo Soulat, Neil Burgess, Maneesh Sahani",
        "paper_link": "https:\/\/papers.nips.cc\/paper_files\/paper\/2022\/file\/003a96110b7134d678cb675c6aea6c7d-Paper-Conference.pdf",
        "abstract_text": "A key goal of unsupervised learning is to go beyond density estimation and sample generation to reveal the structure inherent within observed data. Such structure can be expressed in the pattern of interactions between explanatory latent variables captured through a probabilistic graphical model. Although the learning of structured graphical models has a long history, much recent work in unsupervised modelling has instead emphasised flexible deep-network-based generation, either transforming independent latent generators to model complex data or assuming that distinct observed variables are derived from different latent nodes. Here, we extend amortised variational inference to incorporate structured factors over multiple variables, able to capture the observation-induced posterior dependence between latents that results from \u201cexplaining away\u201d and thus allow complex observations to depend on multiple nodes of a structured graph. We show that appropriately parametrised factors can be combined efficiently with variational message passing in rich graphical structures. We instantiate the framework in nonlinear Gaussian Process Factor Analysis, evaluating the structured recognition framework using synthetic data from known generative processes. We fit the GPFA model to high-dimensional neural spike data from the hippocampus of freely moving rodents, where the model successfully identifies latent signals that correlate with behavioural covariates.\n"
    },
    {
        "year": "2022",
        "title": "NAS-Bench-Graph: Benchmarking Graph Neural Architecture Search",
        "conference_name": "Advances in Neural Information Processing Systems 35  (NeurIPS 2022)",
        "authors": "Yijian Qin, Ziwei Zhang, Xin Wang, Zeyang Zhang, Wenwu Zhu",
        "paper_link": "https:\/\/papers.nips.cc\/paper_files\/paper\/2022\/file\/004bed4e186fdd7ebb73aad6e97c2332-Paper-Datasets_and_Benchmarks.pdf",
        "abstract_text": "Graph neural architecture search (GraphNAS) has recently aroused considerable attention in both academia and industry. However, two key challenges seriously hinder the further research of GraphNAS. First, since there is no consensus for the experimental setting, the empirical results in different research papers are often not comparable and even not reproducible, leading to unfair comparisons. Secondly, GraphNAS often needs extensive computations, which makes it highly inefficient and inaccessible to researchers without access to large-scale computation. To solve these challenges, we propose NAS-Bench-Graph, a tailored benchmark that supports unified, reproducible, and efficient evaluations for GraphNAS. Specifically, we construct a unified, expressive yet compact search space, covering 26,206 unique graph neural network (GNN) architectures and propose a principled evaluation protocol. To avoid unnecessary repetitive training, we have trained and evaluated all of these architectures on nine representative graph datasets, recording detailed metrics including train, validation, and test performance in each epoch, the latency, the number of parameters, etc. Based on our proposed benchmark, the performance of GNN architectures can be directly obtained by a look-up table without any further computation, which enables fair, fully reproducible, and efficient comparisons.  To demonstrate its usage, we make in-depth analyses of our proposed NAS-Bench-Graph, revealing several interesting findings for GraphNAS. We also showcase how the benchmark can be easily compatible with GraphNAS open libraries such as AutoGL and NNI. To the best of our knowledge, our work is the first benchmark for graph neural architecture search.   \n"
    },
    {
        "year": "2022",
        "title": "Fast Bayesian Coresets via Subsampling and Quasi-Newton Refinement",
        "conference_name": "Advances in Neural Information Processing Systems 35  (NeurIPS 2022)",
        "authors": "Cian Naik, Judith Rousseau, Trevor Campbell",
        "paper_link": "https:\/\/papers.nips.cc\/paper_files\/paper\/2022\/file\/005413e90d003d13886019607b037f52-Paper-Conference.pdf",
        "abstract_text": "Bayesian coresets approximate a posterior distribution by building a small weighted subset of the data points. Any inference procedure that is too computationally expensive to be run on the full posterior can instead be run inexpensively on the coreset, with results that approximate those on the full data. However, current approaches are limited by either a significant run-time or the need for the user to specify a low-cost approximation to the full posterior. We propose a Bayesian coreset construction algorithm that first selects a uniformly random subset of data, and then optimizes the weights using a novel quasi-Newton method. Our algorithm is a simple to implement, black-box method, that does not require the user to specify a low-cost posterior approximation. It is the first to come with a general high-probability bound on the KL divergence of the output coreset posterior. Experiments demonstrate that our method provides significant improvements in coreset quality against alternatives with comparable construction times, with far less storage cost and user input required. \n"
    },
    {
        "year": "2022",
        "title": "What You See is What You Classify: Black Box Attributions",
        "conference_name": "Advances in Neural Information Processing Systems 35  (NeurIPS 2022)",
        "authors": "Steven Stalder, Nathanael Perraudin, Radhakrishna Achanta, Fernando Perez-Cruz, Michele Volpi",
        "paper_link": "https:\/\/papers.nips.cc\/paper_files\/paper\/2022\/file\/0073cc73e1873b35345209b50a3dab66-Paper-Conference.pdf",
        "abstract_text": "An important step towards explaining deep image classifiers lies in the identification of image regions that contribute to individual class scores in the model's output. However, doing this accurately is a difficult task due to the black-box nature of such networks. Most existing approaches find such attributions either using activations and gradients or by repeatedly perturbing the input. We instead address this challenge by training a second deep network, the Explainer, to predict attributions for a pre-trained black-box classifier, the Explanandum. These attributions are provided in the form of masks that only show the classifier-relevant parts of an image, masking out the rest. Our approach produces sharper and more boundary-precise masks when compared to the saliency maps generated by other methods. Moreover, unlike most existing approaches, ours is capable of directly generating very distinct class-specific masks in a single forward pass. This makes the proposed method very efficient during inference. We show that our attributions are superior to established methods both visually and quantitatively with respect to the PASCAL VOC-2007 and Microsoft COCO-2014 datasets.\n"
    },
    {
        "year": "2022",
        "title": "Adaptive Interest for Emphatic Reinforcement Learning",
        "conference_name": "Advances in Neural Information Processing Systems 35  (NeurIPS 2022)",
        "authors": "Martin Klissarov, Rasool Fakoor, Jonas W. Mueller, Kavosh Asadi, Taesup Kim, Alexander J. Smola",
        "paper_link": "https:\/\/papers.nips.cc\/paper_files\/paper\/2022\/file\/008079ec00eec9760ee93af5434ee932-Paper-Conference.pdf",
        "abstract_text": "Emphatic algorithms have shown great promise in stabilizing and improving reinforcement learning by selectively emphasizing the update rule. Although the emphasis fundamentally depends on an interest function which defines the intrinsic importance of each state, most approaches simply adopt a uniform interest over all states (except where a hand-designed interest is possible based on domain knowledge). In this paper, we investigate adaptive methods that allow the interest function to dynamically vary over states and iterations. In particular, we leverage meta-gradients to automatically discover online an interest function that would accelerate the agent\u2019s learning process. Empirical evaluations on a wide range of environments show that adapting the interest is key to provide significant gains. Qualitative analysis indicates that the learned interest function emphasizes states of particular importance, such as bottlenecks, which can be especially useful in a transfer learning setting.\n"
    },
    {
        "year": "2022",
        "title": "Scaling & Shifting Your Features: A New Baseline for Efficient Model Tuning",
        "conference_name": "Advances in Neural Information Processing Systems 35  (NeurIPS 2022)",
        "authors": "Dongze Lian, Daquan Zhou, Jiashi Feng, Xinchao Wang",
        "paper_link": "https:\/\/papers.nips.cc\/paper_files\/paper\/2022\/file\/00bb4e415ef117f2dee2fc3b778d806d-Paper-Conference.pdf",
        "abstract_text": "Existing fine-tuning methods either tune all parameters of the pre-trained model (full fine-tuning), which is not efficient, or only tune the last linear layer (linear probing), which suffers a significant accuracy drop compared to the full fine-tuning. In this paper, we propose a new parameter-efficient fine-tuning method termed as SSF, representing that researchers only need to Scale and Shift the deep Features extracted by a pre-trained model to catch up with the performance of full fine-tuning. In this way, SSF also surprisingly outperforms other parameter-efficient fine-tuning approaches even with a smaller number of tunable parameters. Furthermore, different from some existing parameter-efficient fine-tuning methods (e.g., Adapter or VPT) that introduce the extra parameters and computational cost in the training and inference stages, SSF only adds learnable parameters during the training stage, and these additional parameters can be merged into the original pre-trained model weights via re-parameterization in the inference phase. With the proposed SSF, our model obtains 2.46% (90.72% vs. 88.54%) and 11.48% (73.10% vs. 65.57%) performance improvement on FGVC and VTAB-1k in terms of Top-1 accuracy compared to the full fine-tuning but only fine-tuning about 0.3M parameters. We also conduct amounts of experiments in various model families (CNNs, Transformers, and MLPs) and datasets. Results on 26 image classification datasets in total and 3 robustness & out-of-distribution datasets show the effectiveness of SSF. Code is available at https:\/\/github.com\/dongzelian\/SSF. \n"
    },
    {
        "year": "2022",
        "title": "Zero-Shot Video Question Answering via Frozen Bidirectional Language Models",
        "conference_name": "Advances in Neural Information Processing Systems 35  (NeurIPS 2022)",
        "authors": "Antoine Yang, Antoine Miech, Josef Sivic, Ivan Laptev, Cordelia Schmid",
        "paper_link": "https:\/\/papers.nips.cc\/paper_files\/paper\/2022\/file\/00d1f03b87a401b1c7957e0cc785d0bc-Paper-Conference.pdf",
        "abstract_text": "Video question answering (VideoQA) is a complex task that requires diverse multi-modal data for training. Manual annotation of question and answers for videos, however, is tedious and prohibits scalability. To tackle this problem, recent methods consider zero-shot settings with no manual annotation of visual question-answer. In particular, a promising approach adapts frozen autoregressive language models pretrained on Web-scale text-only data to multi-modal inputs. In contrast, we here build on frozen bidirectional language models (BiLM) and show that such an approach provides a stronger and cheaper alternative for zero-shot VideoQA. In particular, (i) we combine visual inputs with the frozen BiLM using light trainable modules, (ii) we train such modules using Web-scraped multi-modal data, and finally (iii) we perform zero-shot VideoQA inference through masked language modeling, where the masked text is the answer to a given question. Our proposed approach, FrozenBiLM, outperforms the state of the art in zero-shot VideoQA by a significant margin on a variety of datasets, including LSMDC-FiB, iVQA, MSRVTT-QA, MSVD-QA, ActivityNet-QA, TGIF-FrameQA, How2QA and TVQA. It also demonstrates competitive performance in the few-shot and fully-supervised setting. Our code and models are publicly available at https:\/\/github.com\/antoyang\/FrozenBiLM.\n"
    },
    {
        "year": "2022",
        "title": "Active Learning with Neural Networks: Insights from Nonparametric Statistics",
        "conference_name": "Advances in Neural Information Processing Systems 35  (NeurIPS 2022)",
        "authors": "Yinglun Zhu, Robert Nowak",
        "paper_link": "https:\/\/papers.nips.cc\/paper_files\/paper\/2022\/file\/01025a4e79355bb37a10ba39605944b5-Paper-Conference.pdf",
        "abstract_text": "Deep neural networks have great representation power, but typically require large numbers of training examples. This motivates deep active learning methods that can significantly reduce the amount of labeled training data. Empirical successes of deep active learning have been recently reported in the literature, however, rigorous label complexity guarantees of deep active learning have remained elusive. This constitutes a significant gap between theory and practice. This paper tackles this gap by providing the first near-optimal label complexity guarantees for deep active learning. The key insight is to study deep active learning from the nonparametric classification perspective. Under standard low noise conditions, we show that active learning with neural networks can provably achieve the minimax label complexity, up to disagreement coefficient and other logarithmic terms. When equipped with an abstention option, we further develop an efficient deep active learning algorithm that achieves $\\mathsf{polylog}(\\frac{1}{\\varepsilon})$ label complexity, without any low noise assumptions.  We also provide extensions of our results beyond the commonly studied Sobolev\/H\\\"older spaces and develop label complexity guarantees for learning in Radon $\\mathsf{BV}^2$ spaces, which have recently been proposed as natural function spaces associated with neural networks."
    }
]